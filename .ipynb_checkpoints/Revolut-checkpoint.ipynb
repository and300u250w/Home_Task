{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Revolut Financial Crime Challenge\n",
    "## Home Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK 1.a - Communication and SQL familiarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examine the following SQL query, and explain clearly and succinctly what it means. Will the query work? Explain why or why not. (15 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```SQL\n",
    "WITH processed_users AS (\n",
    "SELECT left(u.phone_country, 2) AS short_phone_country, u.id \n",
    "FROM users u\n",
    ")\n",
    "SELECT t.user_id, \n",
    "t.merchant_country, \n",
    "sum(t.amount / fx.rate / power(10, cd.exponent)) AS amount \n",
    "FROM transactions t\n",
    "JOIN fx_rates fx ON (fx.ccy = t.currency AND fx.base_ccy = 'EUR')\n",
    "JOIN currency_details cd ON cd.currency = t.currency\n",
    "JOIN processed_users pu ON pu.id = t.user_id\n",
    "WHERE t.source = 'GAIA'\n",
    "AND pu.short_phone_country = t.merchant_country\n",
    "GROUP BY t.user_id, t.merchant_country\n",
    "\n",
    "ORDER BY amount DESC;```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Screenshot%202019-03-13%20at%2000.07.06.png\" width=\"800\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Examine the following SQL query, and explain clearly and succinctly what it means:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Will the query work? Explain why or why not.**\n",
    "___\n",
    "\n",
    "The code above is not working due to this line -> **AND pu.short_phone_country = t.merchant_country**. Compared values are in different formats and that is why result is empty.\n",
    "\n",
    "> pu.short_phone_country  -> **varchar(2)**, ex. HU\n",
    "\n",
    "> t.merchant_country -> **varchar(3)**, ex. HUN\n",
    "\n",
    "\n",
    "The solution for this mistake will be aligning Merchant country code to Phone country code by modifying the string:\n",
    "\n",
    "> Instead of **AND pu.short_phone_country = t.merchant_country** should be **AND pu.short_phone_country = left(t.\"MERCHANT_COUNTRY\",2)**\n",
    "\n",
    "***\n",
    "Additionally, calculation for exchange rate is wrong as well:\n",
    "\n",
    ">Incorrect code - **sum(t.\"AMOUNT\" / fx.rate / power(10, cd.exponent)) AS amount**\n",
    "\n",
    ">Correct code - **sum(t.\"AMOUNT\" * fx.rate / power(10, cd.exponent)) AS amount** \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Screenshot%202019-03-13%20at%2000.09.05.png\" width=\"800\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```SQL\n",
    "WITH processed_users AS (\n",
    "SELECT left(u.\"PHONE_COUNTRY\", 2) AS \n",
    "short_phone_country, u.\"ID\"\n",
    "FROM users u)\n",
    "SELECT t.\"USER_ID\",\n",
    "t.\"MERCHANT_COUNTRY\",\n",
    "sum(t.\"AMOUNT\" * fx.\"rate\" / power(10, cd.exponent)) AS amount\n",
    "FROM transactions t\n",
    "JOIN fx_rates fx ON (fx.ccy = t.\"CURRENCY\" AND fx.base_ccy = 'EUR')\n",
    "JOIN currency_details cd ON cd.ccy = t.\"CURRENCY\"\n",
    "JOIN processed_users pu ON pu.\"ID\" = t.\"USER_ID\"\n",
    "WHERE t.\"SOURCE\" = 'GAIA'\n",
    "AND pu.short_phone_country = left(t.\"MERCHANT_COUNTRY\",2)\n",
    "GROUP BY t.\"USER_ID\", t.\"MERCHANT_COUNTRY\"\n",
    "ORDER BY amount DESC; ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Output result from query above:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Task%201%20results.png\" width=\"800\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK 1.b - Communication and SQL familiarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now itâ€™s your turn! Write a query to identify users whose first transaction was a successful card payment over $10 USD equivalent (10 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correct SQL Query:\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```SQL\n",
    "SELECT *\n",
    "FROM (\n",
    "SELECT DISTINCT ON (tr.\"USER_ID\")\n",
    "\ttr.\"USER_ID\", tr.\"CURRENCY\", tr.\"AMOUNT\", \n",
    "\tCASE WHEN fx.ccy = tr.\"CURRENCY\" THEN tr.\"AMOUNT\"*fx.rate / power(10, cd.exponent) END AS \"AMOUNT_IN_USD\",\n",
    "\ttr.\"CREATED_DATE\" as \"Date_of_First_Transaction\"\n",
    "FROM Public.fx_rates AS fx\n",
    "INNER JOIN transactions as tr ON tr.\"CURRENCY\" = fx.ccy\n",
    "JOIN currency_details cd ON cd.ccy = tr.\"CURRENCY\"\n",
    "WHERE base_ccy = 'USD' \n",
    "    AND tr.\"TYPE\" = 'CARD_PAYMENT' \n",
    "    AND tr.\"STATE\" = 'COMPLETED' \n",
    "ORDER BY tr.\"USER_ID\", tr.\"CREATED_DATE\" ASC) T\n",
    "WHERE \"AMOUNT_IN_USD\" >10;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The query is showing additional columns as a proof that first transaction was made above $10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Task2.png\" width=\"800\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other solution using Python and pandas library\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing pandas library\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading all csv files using pandas\n",
    "currency_details = pd.read_csv('./currency_details.csv')\n",
    "fx_rates = pd.read_csv('./fx_rates.csv')\n",
    "transactions = pd.read_csv('./transactions.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merging fx_rates and currency_details tables\n",
    "fx_rates_exponent = pd.merge(fx_rates, currency_details, how='inner', left_on=\"ccy\", right_on='currency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#taking ex_rate for USD vs other currencies and dropping out unused columns\n",
    "rates_in_usd = fx_rates_exponent[fx_rates_exponent['base_ccy']=='USD'].drop(['currency','iso_code','is_crypto','base_ccy'],axis=1)\n",
    "\n",
    "#Merging transactions and rates_in_usd tables\n",
    "merged_trans = pd.merge(transactions, rates_in_usd, how='inner', left_on='CURRENCY', right_on='ccy')\n",
    "\n",
    "#Creating new column \"Amount in USD\" and applying function Amount * ex_rate / 10**exponent\n",
    "merged_trans['Amount_in_USD'] = merged_trans['AMOUNT']*merged_trans['rate']/10**merged_trans['exponent']\n",
    "\n",
    "#Sorting data by status Completed and by Card Payment\n",
    "merged_trans = merged_trans[(merged_trans['STATE'] ==\"COMPLETED\") & (merged_trans['TYPE'] == 'CARD_PAYMENT')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_trans = merged_trans.sort_values(by = ['USER_ID','CREATED_DATE'],ascending=True ).drop_duplicates(subset = 'USER_ID', keep='first')\n",
    "users_with_10USD_trans = merged_trans[merged_trans['Amount_in_USD']>10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Printing result of first 5 USER_ID of customers with first successful Card transaction over $10\n",
    "users_with_10USD_trans.USER_ID.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To save results into csv file use comand below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving results into csv file\n",
    "users_with_10USD_trans['USER_ID'].to_csv('./users_with_10USD_as_first_transaction.csv',index=False, header='USER_ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK 2.a - Fraudster Radar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find 5 likely fraudsters (not already found in fraudsters.csv!), provide their user_ids, and explain how you found them and why they are likely fraudsters. Use diagrams, illustrations, etc. Show your work! (25 points)\n",
    "_(Note: show your work! We are looking for data-driven techniques. If you use Excel, provide the working file. If you use Python, send us a Jupyter notebook, etc.)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.6.8 |Anaconda, Inc.| (default, Dec 29 2018, 19:04:46) \n",
      "[GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)]\n",
      "Numpy: 1.16.2\n",
      "Pandas: 0.23.0\n",
      "Matplotlib: 2.2.2\n",
      "Seaborn: 0.8.1\n",
      "Scipy: 1.2.1\n"
     ]
    }
   ],
   "source": [
    "#importing pandas library\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "import datetime as dt\n",
    "from tqdm import tqdm\n",
    "\n",
    "print('Python: {}'.format(sys.version))\n",
    "print('Numpy: {}'.format(np.__version__))\n",
    "print('Pandas: {}'.format(pd.__version__))\n",
    "print('Matplotlib: {}'.format(matplotlib.__version__))\n",
    "print('Seaborn: {}'.format(sns.__version__))\n",
    "print('Scipy: {}'.format(scipy.__version__))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Data Set\n",
    "In the following cells, we will import our dataset from a .csv file as a Pandas DataFrame. Furthermore, we will begin exploring the dataset to gain an understanding of the type, quantity, and distribution of data in our dataset. For this purpose, we will use Pandas' built-in describe feature, as well as parameter histograms and a correlation matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading all csv files using pandas\n",
    "currency_details = pd.read_csv('./currency_details.csv')\n",
    "fx_rates = pd.read_csv('./fx_rates.csv')\n",
    "transactions = pd.read_csv('./transactions.csv',index_col=0)\n",
    "users = pd.read_csv('./users.csv',index_col=0)\n",
    "fraudsters = pd.read_csv('./fraudsters.csv',index_col=0)\n",
    "countries = pd.read_csv('./countries.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding to users table information about known fraudsters\n",
    "users[\"Fraudster\"] = users['ID'].isin( fraudsters['user_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merging transactions and rates_in_usd tables\n",
    "fraudsters_trans = pd.merge(transactions, users, how='left',left_on=\"USER_ID\", right_on='ID') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting time to correct time type\n",
    "fraudsters_trans['date_transaction'] =  pd.to_datetime(fraudsters_trans['CREATED_DATE_x'], format='%Y-%m-%d %H:%M:%S.%f')\n",
    "fraudsters_trans['date_acc_created'] =  pd.to_datetime(fraudsters_trans['CREATED_DATE_y'], format='%Y-%m-%d %H:%M:%S.%f')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convering all transactions into GBP\n",
    "fx_rates = pd.merge(fx_rates,currency_details, how='inner',left_on=\"ccy\", right_on='currency').drop(labels=['currency','iso_code','is_crypto'],axis=1)\n",
    "rates_in_gbp = fx_rates[fx_rates['base_ccy']=='GBP']\n",
    "fraudsters_trans = pd.merge(fraudsters_trans,rates_in_gbp, how='left',left_on=\"CURRENCY\", right_on='ccy')\n",
    "fraudsters_trans['Amount_in_GBP'] = (fraudsters_trans['AMOUNT']*fraudsters_trans['rate']/10**fraudsters_trans['exponent'])\n",
    "fraudsters_trans = fraudsters_trans.drop(labels=['base_ccy','rate','ccy','exponent'],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CURRENCY', 'AMOUNT', 'STATE_x', 'CREATED_DATE_x', 'MERCHANT_CATEGORY',\n",
       "       'MERCHANT_COUNTRY', 'ENTRY_METHOD', 'USER_ID', 'TYPE', 'SOURCE', 'ID_x',\n",
       "       'FAILED_SIGN_IN_ATTEMPTS', 'KYC', 'BIRTH_YEAR', 'COUNTRY', 'STATE_y',\n",
       "       'CREATED_DATE_y', 'TERMS_VERSION', 'PHONE_COUNTRY', 'HAS_EMAIL', 'ID_y',\n",
       "       'Fraudster', 'date_transaction', 'date_acc_created', 'Amount_in_GBP'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraudsters_trans.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing unnecessary columns to clean up the dataset and minimize file\n",
    "file_for_data_studio = fraudsters_trans.drop(labels=[\n",
    "    'CREATED_DATE_x',\n",
    "    'ENTRY_METHOD',\n",
    "    'SOURCE',\n",
    "    'ID_x',\n",
    "    'FAILED_SIGN_IN_ATTEMPTS',\n",
    "    'STATE_y',\n",
    "    'CREATED_DATE_y',\n",
    "    'TERMS_VERSION',\n",
    "    'PHONE_COUNTRY',\n",
    "    'HAS_EMAIL',\n",
    "    'ID_y'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CURRENCY', 'AMOUNT', 'STATE_x', 'MERCHANT_CATEGORY',\n",
       "       'MERCHANT_COUNTRY', 'USER_ID', 'TYPE', 'KYC', 'BIRTH_YEAR', 'COUNTRY',\n",
       "       'Fraudster', 'date_transaction', 'date_acc_created', 'Amount_in_GBP'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_for_data_studio.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_for_data_studio = file_for_data_studio.sort_values(by = ['USER_ID','date_acc_created'],ascending=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving cleaned data set for Data Studio\n",
    "file_for_data_studio.to_csv('./file_for_data_studio.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Data to train ML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating new columns with time diference in seconds between transactions and account creations.\n",
    "fraudsters_trans[\"dif_date\"] = fraudsters_trans['date_transaction'] - fraudsters_trans['date_acc_created']\n",
    "fraudsters_trans[\"dif_date\"] = fraudsters_trans[\"dif_date\"].dt.total_seconds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CURRENCY', 'AMOUNT', 'STATE_x', 'CREATED_DATE_x', 'MERCHANT_CATEGORY',\n",
       "       'MERCHANT_COUNTRY', 'ENTRY_METHOD', 'USER_ID', 'TYPE', 'SOURCE', 'ID_x',\n",
       "       'FAILED_SIGN_IN_ATTEMPTS', 'KYC', 'BIRTH_YEAR', 'COUNTRY', 'STATE_y',\n",
       "       'CREATED_DATE_y', 'TERMS_VERSION', 'PHONE_COUNTRY', 'HAS_EMAIL', 'ID_y',\n",
       "       'Fraudster', 'date_transaction', 'date_acc_created', 'Amount_in_GBP',\n",
       "       'dif_date'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraudsters_trans.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraudsters_trans = fraudsters_trans.drop(labels=[\n",
    "    'CREATED_DATE_x',\n",
    "    'date_acc_created',\n",
    "    'date_transaction',\n",
    "    'ID_x',\n",
    "    'CREATED_DATE_y',\n",
    "    'HAS_EMAIL',\n",
    "    'ID_y'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CURRENCY', 'AMOUNT', 'STATE_x', 'MERCHANT_CATEGORY',\n",
       "       'MERCHANT_COUNTRY', 'ENTRY_METHOD', 'USER_ID', 'TYPE', 'SOURCE',\n",
       "       'FAILED_SIGN_IN_ATTEMPTS', 'KYC', 'BIRTH_YEAR', 'COUNTRY', 'STATE_y',\n",
       "       'TERMS_VERSION', 'PHONE_COUNTRY', 'Fraudster', 'Amount_in_GBP',\n",
       "       'dif_date'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraudsters_trans.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:54<00:00,  3.37s/it]\n"
     ]
    }
   ],
   "source": [
    "#Converitng all test into numbers by using hash\n",
    "list_for_converting = [\"CURRENCY\",\"STATE_x\", \"MERCHANT_CATEGORY\", \"MERCHANT_COUNTRY\",\"ENTRY_METHOD\", \"TYPE\", \"SOURCE\",\"KYC\", \"COUNTRY\", \"PHONE_COUNTRY\",'Fraudster']\n",
    "for conv in tqdm(list_for_converting):\n",
    "    hash_words = {word: hash(word) for word in fraudsters_trans[conv].unique()}\n",
    "    for i in hash_words:\n",
    "        fraudsters_trans[conv] = fraudsters_trans[conv].replace(i, hash_words[i])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniq_users = fraudsters_trans[\"USER_ID\"].unique()\n",
    "hash_words = {word: hash(word) for word in uniq_users}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|â–ˆâ–ˆâ–ˆâ–‹      | 2987/8021 [04:24<12:38,  6.64it/s]"
     ]
    }
   ],
   "source": [
    "for i in tqdm(hash_words):\n",
    "        fraudsters_trans['USER_ID'] = fraudsters_trans[\"USER_ID\"].replace(i, hash_words[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fraudsters_trans.to_csv('./cleaned_data.csv',index=False)\n",
    "fraudsters_trans = pd.read_csv(\"./cleaned_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_classes = pd.value_counts(fraudsters_trans['Fraudster'], sort = True).sort_index()\n",
    "count_classes.plot(kind = 'bar')\n",
    "plt.title(\"Fraud class histogram\")\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Frequency\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the shape of the data\n",
    "data = fraudsters_trans.sample(frac=0.5, random_state = 1)\n",
    "print(data.shape)\n",
    "print(data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histograms of each parameter \n",
    "data.hist(figsize = (20, 20))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine number of fraud cases in dataset\n",
    "\n",
    "Fraud = fraudsters_trans[fraudsters_trans['Fraudster'] == 1]\n",
    "Valid = data[data['Fraudster'] == 0]\n",
    "\n",
    "outlier_fraction = len(Fraud)/float(len(Valid))\n",
    "print(outlier_fraction)\n",
    "\n",
    "print('Fraud Cases: {}'.format(len(data[data['Fraudster'] == 1])))\n",
    "print('Valid Transactions: {}'.format(len(data[data['Fraudster'] == 0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix\n",
    "corrmat = data.corr()\n",
    "fig = plt.figure(figsize = (12, 9))\n",
    "\n",
    "sns.heatmap(corrmat, vmax = .8, square = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the columns from the dataFrame\n",
    "columns = data.columns.tolist()\n",
    "\n",
    "# Filter the columns to remove data we do not want\n",
    "columns = [c for c in columns if c not in [\"Fraudster\", \"HASHED_USER_ID\"]]\n",
    "\n",
    "# Store the variable we'll be predicting on\n",
    "target = \"Fraudster\"\n",
    "\n",
    "X = data[columns]\n",
    "Y = data[target]\n",
    "\n",
    "# Print shapes\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Unsupervised Outlier Detection\n",
    "Now that we have processed our data, we can begin deploying our machine learning algorithms. We will use the following techniques:\n",
    "\n",
    "Local Outlier Factor (LOF)\n",
    "\n",
    "The anomaly score of each sample is called Local Outlier Factor. It measures the local deviation of density of a given sample with respect to its neighbors. It is local in that the anomaly score depends on how isolated the object is with respect to the surrounding neighborhood.\n",
    "\n",
    "Isolation Forest Algorithm\n",
    "\n",
    "The IsolationForest â€˜isolatesâ€™ observations by randomly selecting a feature and then randomly selecting a split value between the maximum and minimum values of the selected feature.\n",
    "\n",
    "Since recursive partitioning can be represented by a tree structure, the number of splittings required to isolate a sample is equivalent to the path length from the root node to the terminating node.\n",
    "\n",
    "This path length, averaged over a forest of such random trees, is a measure of normality and our decision function.\n",
    "\n",
    "Random partitioning produces noticeably shorter paths for anomalies. Hence, when a forest of random trees collectively produce shorter path lengths for particular samples, they are highly likely to be anomalies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "# define random states\n",
    "state = 1\n",
    "\n",
    "# define outlier detection tools to be compared\n",
    "classifiers = {\n",
    "    \"Isolation Forest\": IsolationForest(max_samples=len(X),\n",
    "                                        contamination=outlier_fraction,\n",
    "                                        random_state=state),\n",
    "    \"Local Outlier Factor\": LocalOutlierFactor(\n",
    "        n_neighbors=20,\n",
    "        contamination=outlier_fraction)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "plt.figure(figsize=(9, 7))\n",
    "n_outliers = len(Fraud)\n",
    "\n",
    "\n",
    "for i, (clf_name, clf) in tqdm(enumerate(classifiers.items())):\n",
    "    \n",
    "    # fit the data and tag outliers\n",
    "    if clf_name == \"Local Outlier Factor\":\n",
    "        y_pred = clf.fit_predict(X)\n",
    "        scores_pred = clf.negative_outlier_factor_\n",
    "    else:\n",
    "        clf.fit(X)\n",
    "        scores_pred = clf.decision_function(X)\n",
    "        y_pred = clf.predict(X)\n",
    "    \n",
    "    # Reshape the prediction values to 0 for valid, 1 for fraud. \n",
    "    y_pred[y_pred == 1] = 0\n",
    "    y_pred[y_pred == -1] = 1\n",
    "    \n",
    "    n_errors = (y_pred != Y).sum()\n",
    "    \n",
    "    # Run classification metrics\n",
    "    print('{}: {}'.format(clf_name, n_errors))\n",
    "    print(accuracy_score(Y, y_pred))\n",
    "    print(classification_report(Y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision = 0.03. The rate of true positive in all positive cases.\n",
    "Recall = 0.06. The rate of true positive in all true cases.\n",
    "F1-score = 0.04\n",
    "Model is not working "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### As a trained model is working with so small accuracny I'll review account activity manualy using DataStudio. Full report can be found under this [Link](https://datastudio.google.com/open/1cv5JXuZliSNLDmqfMXP4A69-kvwtpl-_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"1000\" height=\"1360\" src=\"https://datastudio.google.com/embed/reporting/1cv5JXuZliSNLDmqfMXP4A69-kvwtpl-_/page/omhk\" frameborder=\"0\" style=\"border:0\" allowfullscreen></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML('<iframe width=\"1000\" height=\"1360\" src=\"https://datastudio.google.com/embed/reporting/1cv5JXuZliSNLDmqfMXP4A69-kvwtpl-_/page/omhk\" frameborder=\"0\" style=\"border:0\" allowfullscreen></iframe>'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
